{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24cc04ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import arnie\n",
    "from arnie.utils import *\n",
    "from arnie.utils import _group_into_non_conflicting_bp\n",
    "\n",
    "# import csv for pseudoknot predictions\n",
    "\n",
    "def get_csv(csv_loc):\n",
    "    df = pd.read_csv(csv_loc)\n",
    "    return df \n",
    "\n",
    "# extract locations for each pseudoknot along with dotbracket structures\n",
    "\n",
    "def check_if_shapeknots(name, shapeknots_names):\n",
    "    for program in shapeknots_names: \n",
    "        if name == program: \n",
    "            return True\n",
    "\n",
    "def get_info(df):\n",
    "    starts = df['start'].to_list()\n",
    "    ends = df['end'].to_list()\n",
    "    sequences = df['sequence'].to_list()\n",
    "    dotbrackets = df['struct'].to_list()\n",
    "    \n",
    "    return starts, ends, sequences, dotbrackets\n",
    "\n",
    "# use the below function only for dataframe analysis using shape-directed threshknot csvs\n",
    "\n",
    "def get_info_from_shapeknots(df):\n",
    "    starts = (df['start']-1).to_list()\n",
    "    ends = df['end'].to_list()\n",
    "    sequences = df['sequence'].to_list()\n",
    "    dotbrackets = df['threshknot_structure'].to_list()\n",
    "    \n",
    "    return starts, ends, sequences, dotbrackets\n",
    "\n",
    "# import shapeknots data and convert to list\n",
    "\n",
    "def get_shape_data(filename):\n",
    "    shape = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            shape.append(line)\n",
    "            \n",
    "    for i in range(len(shape)):\n",
    "        shape[i] = (-1) if shape[i] == 'nan' else float(shape[i])\n",
    "        \n",
    "    return shape\n",
    "\n",
    "# use Rachael's function to compare shape and dotbracket structure and return ranking\n",
    "# research more official methods for comparing with shape data \n",
    "\n",
    "def evaluate_L1_shape_score(s,shape):\n",
    "    score = 0\n",
    "    for c,react in zip(s,shape):\n",
    "        if (c==\".\" and react>0.25) or (c!=\".\" and react<0.5):\n",
    "            score += 1\n",
    "    return score/len(s)\n",
    "\n",
    "# get locations of pseudoknotted base pairs in a window\n",
    "\n",
    "def get_groups(dotbracket):\n",
    "    bp_list = convert_dotbracket_to_bp_list(dotbracket, allow_pseudoknots=True)\n",
    "    groups = _group_into_non_conflicting_bp(bp_list)\n",
    "    return groups\n",
    "\n",
    "def get_pk_bp_locs(groups):\n",
    "    pk_bp_list = []\n",
    "    pk_bp_locs = []\n",
    "    for i, lists in enumerate(groups):\n",
    "        if i == 0: \n",
    "            None\n",
    "        else: \n",
    "            length = len(lists)\n",
    "            for idx in range(length):\n",
    "                bp = lists[idx]\n",
    "                pk_bp_list.append(bp)\n",
    "                pk_bp_locs.append(bp[0])\n",
    "                pk_bp_locs.append(bp[1])             \n",
    "    pk_bp_locs.sort()\n",
    "    return pk_bp_locs, pk_bp_list\n",
    "\n",
    "def get_pk_bp_struct(pk_bp_locs, dotbracket):\n",
    "    pk_bp_struct = []\n",
    "    for idx in pk_bp_locs:\n",
    "        bracket = dotbracket[idx]\n",
    "        pk_bp_struct.append(bracket)\n",
    "    return pk_bp_struct\n",
    "\n",
    "# rank PKs based on theoretically thermodynamic stability: find free energy using nupack capability in arnie \n",
    "\n",
    "def get_pk_rank(pk_bp_locs, dotbracket):\n",
    "    pk_rank = 0\n",
    "    for idx in pk_bp_locs:\n",
    "        if (idx != 119) and (dotbracket[idx] == dotbracket[idx+1]):\n",
    "            pk_rank += 0.5   \n",
    "    for idx in pk_bp_locs: \n",
    "        if (idx != 119) and (dotbracket[idx] != dotbracket[idx+1]):\n",
    "            if dotbracket[idx+1] == '.':\n",
    "                pk_rank += 0\n",
    "            else:\n",
    "                pk_rank -= 1\n",
    "    for idx in pk_bp_locs: \n",
    "        if (idx != 0) and (dotbracket[idx] != dotbracket[idx-1]):\n",
    "            if dotbracket[idx-1] == '.':\n",
    "                pk_rank += 0\n",
    "            else:\n",
    "                pk_rank -= 1\n",
    "    return pk_rank\n",
    "\n",
    "# rank PKs on consensus with other predictions\n",
    "\n",
    "def get_bp_list(dotbracket):\n",
    "    bp_list = convert_dotbracket_to_bp_list(dotbracket, allow_pseudoknots=True)\n",
    "    return bp_list\n",
    "\n",
    "def compare_bp_lists(bp_list1, bp_list2):\n",
    "    bp_list_score = 0\n",
    "    for bp1 in bp_list1: \n",
    "        for bp2 in bp_list2: \n",
    "            if bp1 == bp2: \n",
    "                bp_list_score += 1\n",
    "        # divide by total number of base pairs in bp_list1 to normalize results\n",
    "    return bp_list_score/len(bp_list1)\n",
    "\n",
    "def check_if_same_window(start1, program2_starts):\n",
    "    for start2 in program2_starts: \n",
    "        if start1 == start2: \n",
    "            return True\n",
    "\n",
    "def get_consensus_scores(program1_starts, bp_lists1, program2_starts, bp_lists2):\n",
    "    scores = []\n",
    "    for i, start1 in enumerate(program1_starts):\n",
    "        if check_if_same_window(start1, program2_starts):\n",
    "            for idx, start2 in enumerate(program2_starts):\n",
    "                if start1 == start2:\n",
    "                    bp_list1 = bp_lists1[i]\n",
    "                    bp_list2 = bp_lists2[idx]\n",
    "                    bp_list_score = compare_bp_lists(bp_list1, bp_list2)\n",
    "                    scores.append(bp_list_score)\n",
    "        elif not check_if_same_window(start1, program2_starts):\n",
    "            scores.append(0)\n",
    "    return scores\n",
    "\n",
    "def get_weighted_consensus(starts_by_program, bp_lists_by_program):\n",
    "    weighted_avgs = []\n",
    "    for idx1, program1_starts in enumerate(starts_by_program):\n",
    "        program1_bp_lists = bp_lists_by_program[idx1]\n",
    "        program1_consensus_scores = []\n",
    "        for idx2, program2_starts in enumerate(starts_by_program):\n",
    "            if idx1 != idx2:\n",
    "                program2_bp_lists = bp_lists_by_program[idx2]\n",
    "                consensus_scores = get_consensus_scores(program1_starts, program1_bp_lists, program2_starts, program2_bp_lists)\n",
    "                program1_consensus_scores.append(consensus_scores)\n",
    "        \n",
    "        program1_weighted_avgs = []\n",
    "        for i in range(len(program1_consensus_scores[0])):\n",
    "            window = []\n",
    "            for program in program1_consensus_scores:\n",
    "                window.append(program[i])\n",
    "            weighted_avg = sum(window)/len(window)\n",
    "            program1_weighted_avgs.append(weighted_avg)\n",
    "            \n",
    "        weighted_avgs = weighted_avgs + program1_weighted_avgs\n",
    "    return weighted_avgs\n",
    "\n",
    "#### this function takes as input a list of dotbracket structures and bp_lists \n",
    "    #for pseudoknots predicted in the same window\n",
    "#### returns as output a score for consensus of all to all for each structure\n",
    "\n",
    "def all_to_all(structs_list, bp_lists):\n",
    "    scores = []\n",
    "    for idx, struct in enumerate(structs_list): \n",
    "        score = 0\n",
    "        for i, char in enumerate(struct):\n",
    "            same_np = 0\n",
    "            for other_struct in structs_list: \n",
    "                if (char == '.') and (char == other_struct[i]):\n",
    "                    same_np += 1\n",
    "            if same_np == len(structs_list):\n",
    "                score += 1\n",
    "        for bp in bp_lists[idx]:\n",
    "            same_bp = 0\n",
    "            for bp_list in bp_lists: \n",
    "                for bp2 in bp_list:\n",
    "                    if bp == bp2:\n",
    "                        same_bp += 1\n",
    "            if same_bp == len(bp_lists):\n",
    "                score += 1\n",
    "        \n",
    "        count = 0\n",
    "        for char in struct:\n",
    "            if char == '.':\n",
    "                count += 1\n",
    "        count += len(bp_lists[idx])\n",
    "        \n",
    "        score = score/count\n",
    "        scores.append(score)\n",
    "        \n",
    "    return scores\n",
    "\n",
    "# create new dataframe with rankings\n",
    "\n",
    "def get_df(all_programs, starts, ends, sequences, dotbrackets, shape_scores, pk_bp_shape_scores, ranks, weighted_consensus_avgs, weighted_pk_bps_consensus_avgs):\n",
    "    PK_list = zip(all_programs, starts, ends, sequences, dotbrackets, shape_scores, pk_bp_shape_scores, ranks, weighted_consensus_avgs, weighted_pk_bps_consensus_avgs)\n",
    "    df = pd.DataFrame(PK_list, columns = ['program', 'start', 'end', 'sequence', 'structure', 'shape_score', 'pk_bp_shape_score', 'rank', 'weighted_consensus_score', 'weighted_pk_bp_consensus_score'])\n",
    "    ranked_df = df.sort_values('pk_bp_shape_score', ascending=False)\n",
    "    return ranked_df\n",
    "\n",
    "def average_consensus(df):\n",
    "    \n",
    "    #goal get a list of starts for pks without repeats\n",
    "    starts = []\n",
    "    all_starts = df['start'].to_list()\n",
    "    for idx in all_starts:\n",
    "        if idx not in starts:\n",
    "            starts.append(idx)\n",
    "    \n",
    "    #goal: get a list of locations for pks predicted multiple times\n",
    "    locations = []\n",
    "    for idx in starts: \n",
    "        specdf = df[df['start'] == idx]\n",
    "        all_locations = specdf['start'].to_list()\n",
    "        if len(all_locations) > 1:\n",
    "            locations.append(idx)\n",
    "            \n",
    "    # goal: get list of weighted consensus scores for each location \n",
    "    \n",
    "    all_scores = []\n",
    "    all_pk_bp_scores = []\n",
    "    #note that all_scores is a list containing lists of consensus scores for each program in each window\n",
    "    for idx in locations: \n",
    "        specdf = testdf[testdf['start'] == idx]\n",
    "        scores_list = specdf['weighted_consensus_score'].to_list()\n",
    "        pk_bp_scores_list = specdf['weighted_pk_bp_consensus_score'].to_list()\n",
    "        all_scores.append(scores_list)\n",
    "        all_pk_bp_scores.append(pk_bp_scores_list)\n",
    "    \n",
    "    # goal: average the scores for each window and add to a new list\n",
    "    \n",
    "    averaged_scores = []\n",
    "    averaged_pk_bp_scores = []\n",
    "    #note that averaged_scores is a list of the averaged scores for each location \n",
    "    for window in all_scores: \n",
    "        window_avg = sum(window)/len(window)\n",
    "        averaged_scores.append(window_avg)\n",
    "    for window in all_pk_bp_scores:\n",
    "        window_avg = sum(window)/len(window)\n",
    "        averaged_pk_bp_scores.append(window_avg)\n",
    "        \n",
    "    #goal: create a dataframe that contains the location and the consensus scores for all pks\n",
    "    \n",
    "    pks_list = zip(locations, averaged_scores, averaged_pk_bp_scores)\n",
    "    df = pd.DataFrame(pks_list, columns = ['location', 'average_consensus_score', 'average_pk_bp_consensus_score'])\n",
    "    return df\n",
    "\n",
    "# get consensus score for only pk bps\n",
    "    \n",
    "# put it all together\n",
    "\n",
    "def score_pk_overall(names, shapeknots_names, path, shape_file):\n",
    "    \n",
    "    all_programs = []\n",
    "    starts = []\n",
    "    ends = []\n",
    "    sequences = []\n",
    "    dotbrackets = []\n",
    "    \n",
    "    starts_by_program = []\n",
    "    ends_by_program = []\n",
    "    sequences_by_program = []\n",
    "    dotbrackets_by_program = []\n",
    "    bp_lists_by_program = []\n",
    "    pk_bp_lists_by_program = []\n",
    "    \n",
    "    for name in names: \n",
    "        df = get_csv(path + name + '.csv')\n",
    "        \n",
    "        if check_if_shapeknots(name, shapeknots_names):\n",
    "            program_starts, program_ends, program_sequences, program_dotbrackets = get_info_from_shapeknots(df)\n",
    "        elif not check_if_shapeknots(name, shapeknots_names):\n",
    "            program_starts, program_ends, program_sequences, program_dotbrackets = get_info(df)\n",
    "        \n",
    "        for i in range(len(program_starts)):\n",
    "            all_programs.append(name)\n",
    "            \n",
    "        program_bp_lists = []\n",
    "        for dotbracket in program_dotbrackets: \n",
    "            bp_list = get_bp_list(dotbracket)\n",
    "            program_bp_lists.append(bp_list)\n",
    "            \n",
    "        pk_bp_list_by_program = []\n",
    "        pk_bp_locs_by_program = []\n",
    "        pk_bp_structs_by_program = []\n",
    "        for i, struct in enumerate(program_dotbrackets):\n",
    "            groups = get_groups(struct)\n",
    "            pk_bp_loc, pk_bp_list = get_pk_bp_locs(groups)\n",
    "            pk_bp_struct = get_pk_bp_struct(pk_bp_loc, struct)\n",
    "        \n",
    "            pk_bp_locs_by_program.append(pk_bp_loc)\n",
    "            pk_bp_structs_by_program.append(pk_bp_struct)\n",
    "            pk_bp_list_by_program.append(pk_bp_list)\n",
    "        \n",
    "        \n",
    "        starts = starts + program_starts\n",
    "        ends = ends + program_ends\n",
    "        sequences = sequences + program_sequences\n",
    "        dotbrackets = dotbrackets + program_dotbrackets\n",
    "        \n",
    "        starts_by_program.append(program_starts)\n",
    "        ends_by_program.append(program_ends)\n",
    "        sequences_by_program.append(program_sequences)\n",
    "        dotbrackets_by_program.append(program_dotbrackets)\n",
    "        bp_lists_by_program.append(program_bp_lists)\n",
    "        pk_bp_lists_by_program.append(pk_bp_list_by_program)\n",
    "        \n",
    "    \n",
    "    # get rough score for consensus with shape data for entire window\n",
    "    \n",
    "    full_shape = get_shape_data(shape_file)\n",
    "    shapes = []\n",
    "    for i, start in enumerate(starts):\n",
    "        end = ends[i]\n",
    "        shape_window = full_shape[start:end]\n",
    "        shapes.append(shape_window)\n",
    "    \n",
    "    shape_scores = []\n",
    "    for i, struct in enumerate(dotbrackets):\n",
    "        shape = shapes[i]\n",
    "        score = evaluate_L1_shape_score(struct, shape)\n",
    "        shape_scores.append(score)\n",
    "\n",
    "    # get score for shape consensus with only pk bps\n",
    "\n",
    "    pk_bp_lists = []\n",
    "    pk_bp_locs = []\n",
    "    pk_bp_structs = []\n",
    "    for i, struct in enumerate(dotbrackets):\n",
    "        groups = get_groups(struct)\n",
    "        pk_bp_loc, pk_bp_list = get_pk_bp_locs(groups)\n",
    "        pk_bp_struct = get_pk_bp_struct(pk_bp_loc, struct)\n",
    "        \n",
    "        pk_bp_locs.append(pk_bp_loc)\n",
    "        pk_bp_structs.append(pk_bp_struct)\n",
    "        pk_bp_lists.append(pk_bp_list)\n",
    "        \n",
    "    pk_bp_shapes = []\n",
    "    for i, locs in enumerate(pk_bp_locs):\n",
    "        pk_bp_shapes_window = []\n",
    "        shape_window = shapes[i]\n",
    "        for idx in locs:\n",
    "            shape = shape_window[idx]\n",
    "            pk_bp_shapes_window.append(shape)\n",
    "        pk_bp_shapes.append(pk_bp_shapes_window)\n",
    "        \n",
    "    pk_bp_shape_scores = []\n",
    "    for i, struct in enumerate(pk_bp_structs):\n",
    "        pk_bp_shape_window = pk_bp_shapes[i]\n",
    "        score = evaluate_L1_shape_score(struct, pk_bp_shape_window)\n",
    "        pk_bp_shape_scores.append(score)\n",
    "    \n",
    "    # get rough ranking for likelihood of PK\n",
    "        \n",
    "    ranks = []\n",
    "    for i, struct in enumerate(dotbrackets): \n",
    "        rank = get_pk_rank(pk_bp_locs[i], struct)\n",
    "        ranks.append(rank)\n",
    "        \n",
    "    # get consensus score with other predictions\n",
    "    \n",
    "    weighted_consensus_avgs = get_weighted_consensus(starts_by_program, bp_lists_by_program)\n",
    "    \n",
    "    # get consensus scores for pk bps only \n",
    "    \n",
    "    weighted_pk_bps_consensus_avgs = get_weighted_consensus(starts_by_program, pk_bp_lists_by_program)\n",
    "    \n",
    "    # put it all together into a dataframe\n",
    "        \n",
    "    df = get_df(all_programs, starts, ends, sequences, dotbrackets, shape_scores, pk_bp_shape_scores, ranks, weighted_consensus_avgs, weighted_pk_bps_consensus_avgs)\n",
    "    avg_df = average_consensus(df)\n",
    "    \n",
    "    # from dataframe, pull list of all locations that are repeated (get seqs as well)\n",
    "    # from dataframe, pull lists of all consensus scores and pk consensus scores that have same location \n",
    "    # average each list and put them in new list\n",
    "    # make new dataframe\n",
    "    \n",
    "    return df, avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c00dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['incarnato_invitro', 'knotty', 'threshknot', 'zhang_invivo', 'incarnato_invivo', 'pknots', 'zhang_invitro', 'pyle', 'spotrna']\n",
    "shapeknots_names = ['incarnato_invitro', 'zhang_invivo', 'incarnato_invivo', 'zhang_invitro', 'pyle']\n",
    "path = '/home/gnye8/Desktop/PK_research/pipeline_results/direct_output/'\n",
    "shape = '/home/gnye8/Desktop/PK_research/SSRP_work/shape_data/incarnato_invivo_reactivity-Copy1.csv'\n",
    "\n",
    "\n",
    "test_df = score_pk_overall(names, shapeknots_names, path, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99b67bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b311cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcdb84af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_consensus(df):\n",
    "    \n",
    "    #goal get a list of starts for pks without repeats\n",
    "    starts = []\n",
    "    all_starts = df['start'].to_list()\n",
    "    for idx in all_starts:\n",
    "        if idx not in starts:\n",
    "            starts.append(idx)\n",
    "    \n",
    "    #goal: get a list of locations for pks predicted multiple times\n",
    "    locations = []\n",
    "    for idx in starts: \n",
    "        specdf = df[df['start'] == idx]\n",
    "        all_locations = specdf['start'].to_list()\n",
    "        if len(all_locations) > 1:\n",
    "            locations.append(idx)\n",
    "            \n",
    "    # goal: get list of weighted consensus scores for each location \n",
    "    \n",
    "    all_scores = []\n",
    "    all_pk_bp_scores = []\n",
    "    #note that all_scores is a list containing lists of consensus scores for each program in each window\n",
    "    for idx in locations: \n",
    "        specdf = df[df['start'] == idx]\n",
    "        scores_list = specdf['weighted_consensus_score'].to_list()\n",
    "        pk_bp_scores_list = specdf['weighted_pk_bp_consensus_score'].to_list()\n",
    "        all_scores.append(scores_list)\n",
    "        all_pk_bp_scores.append(pk_bp_scores_list)\n",
    "    \n",
    "    # goal: average the scores for each window and add to a new list\n",
    "    \n",
    "    averaged_scores = []\n",
    "    averaged_pk_bp_scores = []\n",
    "    #note that averaged_scores is a list of the averaged scores for each location \n",
    "    for window in all_scores: \n",
    "        window_avg = sum(window)/len(window)\n",
    "        averaged_scores.append(window_avg)\n",
    "    for window in all_pk_bp_scores:\n",
    "        window_avg = sum(window)/len(window)\n",
    "        averaged_pk_bp_scores.append(window_avg)\n",
    "        \n",
    "    #goal: create a dataframe that contains the location and the consensus scores for all pks\n",
    "    \n",
    "    pks_list = zip(locations, averaged_scores, averaged_pk_bp_scores)\n",
    "    df = pd.DataFrame(pks_list, columns = ['location', 'average_consensus_score', 'average_pk_bp_consensus_score'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "02c70581",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/home/gnye8/Desktop/PK_research/pipeline_results/analysis_output/first_weighted_consensus.csv')\n",
    "\n",
    "avg_df = average_consensus(df1)\n",
    "avg_df.to_csv('/home/gnye8/Desktop/PK_research/pipeline_results/analysis_output/avg_consensus_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "32b45bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>average_consensus_score</th>\n",
       "      <th>average_pk_bp_consensus_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>18680</td>\n",
       "      <td>0.329082</td>\n",
       "      <td>0.135218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>6680</td>\n",
       "      <td>0.293381</td>\n",
       "      <td>0.128681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>29560</td>\n",
       "      <td>0.272369</td>\n",
       "      <td>0.156362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>10400</td>\n",
       "      <td>0.267670</td>\n",
       "      <td>0.057692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22880</td>\n",
       "      <td>0.260216</td>\n",
       "      <td>0.114886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>12800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>6000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>27360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>5320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     location  average_consensus_score  average_pk_bp_consensus_score\n",
       "144     18680                 0.329082                       0.135218\n",
       "239      6680                 0.293381                       0.128681\n",
       "331     29560                 0.272369                       0.156362\n",
       "325     10400                 0.267670                       0.057692\n",
       "5       22880                 0.260216                       0.114886\n",
       "..        ...                      ...                            ...\n",
       "282     12800                 0.000000                       0.000000\n",
       "23      22280                 0.000000                       0.000000\n",
       "318      6000                 0.000000                       0.000000\n",
       "541     27360                 0.000000                       0.000000\n",
       "313      5320                 0.000000                       0.000000\n",
       "\n",
       "[570 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_df.sort_values('average_consensus_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "40f0ff55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "94\n",
      "UAUGAGGAUCAAGAUGCACUUUUCGCAUAUACAAAACGUAAUGUCAUCCCUACUAUAACUCAAAUGAAUCUUAAGUAUGCCAUUAGUGCAAAGA\n"
     ]
    }
   ],
   "source": [
    "seq = 'UAUGAGGAUCAAGAUGCACUUUUCGCAUAUACAAAACGUAAUGUCAUCCCUACUAUAACUCAAAUGAAUCUUAAGUAUGCCAUUAGUGCAAAGAAUAGAGCUCGCACCGUAGCUGGUGUC'\n",
    "print(len(seq))\n",
    "seq2 = seq[0:94]\n",
    "print(len(seq2))\n",
    "print(seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3146c642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e72e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f2ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6533be17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed78cc29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac452a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be994c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c83d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e61157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
